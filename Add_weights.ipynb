{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition explicity wants us to not misclassify examples which have identities. One way to ensure the training takes this into consideration is to modify the loss to a weighted cross entropy. This overweighs examples that are likely to get misclassified. \n",
    "\n",
    "Shown below is the general algorithm used to reweigh samples. This was repeated for p1 and p2 of the training data. Additionally different combinations of the weighing parameters were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:07:02.857711Z",
     "start_time": "2019-06-08T23:07:02.852759Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:07:14.519675Z",
     "start_time": "2019-06-08T23:07:02.860703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6229878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>Beyond the non-existent customer service, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6116726</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>a</td>\n",
       "      <td>Lol. The Idiocracy pResidency continues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6157047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>\"someone had jammed a British Fantasy Series M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>719889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>\"Social contract,\" \"will of the gods,\" \"divine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1019477</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>a</td>\n",
       "      <td>Well, perhaps the money to fix this should com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1  2                                                  3\n",
       "0  6229878  0.000000  a  Beyond the non-existent customer service, the ...\n",
       "1  6116726  0.500000  a         Lol. The Idiocracy pResidency continues...\n",
       "2  6157047  0.000000  a  \"someone had jammed a British Fantasy Series M...\n",
       "3   719889  0.000000  a  \"Social contract,\" \"will of the gods,\" \"divine...\n",
       "4  1019477  0.166667  a  Well, perhaps the money to fix this should com..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data with identities\n",
    "p1_iden=pd.read_csv(pathlib.Path.cwd().joinpath('data_float_all_cols', 'p1', 'train.tsv'), sep='\\t')\n",
    "#read data without identities\n",
    "p1=pd.read_csv(pathlib.Path.cwd().joinpath('data_float', 'p1', 'train.tsv'), sep='\\t', header=None)\n",
    "p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:10:47.864104Z",
     "start_time": "2019-06-08T23:10:47.185836Z"
    }
   },
   "outputs": [],
   "source": [
    "p1[3]=p1[3].replace(r'\\t', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:11:02.042825Z",
     "start_time": "2019-06-08T23:11:02.037839Z"
    }
   },
   "outputs": [],
   "source": [
    "identity_cols = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:11:15.473265Z",
     "start_time": "2019-06-08T23:11:15.458303Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_weights(df_iden):\n",
    "    df=df_iden.copy(deep=True)\n",
    "    for column in identity_cols+['target']:\n",
    "        df[column] = np.where(df[column] >= 0.5, True, False)\n",
    "    sample_weights = np.ones(df.shape[0], dtype=np.float32)\n",
    "    #Increase the sample weight by the number of true identity columns\n",
    "    sample_weights += df[identity_cols].sum(axis=1)\n",
    "    #If the target is true increase the weight by the number of 'FALSE' identity columns\n",
    "    sample_weights += df['target'] * (~df[identity_cols]).sum(axis=1)\n",
    "    #If the target is false, increase the weight by the number of 'TRUE' identity columns, multiplied by 5. \n",
    "    sample_weights += (~df['target']) * df[identity_cols].sum(axis=1) * 5\n",
    "    #Average these\n",
    "    sample_weights /= sample_weights.mean()\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:11:17.129562Z",
     "start_time": "2019-06-08T23:11:16.463345Z"
    }
   },
   "outputs": [],
   "source": [
    "p1['weights']=make_weights(p1_iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T23:11:40.923807Z",
     "start_time": "2019-06-08T23:11:21.056841Z"
    }
   },
   "outputs": [],
   "source": [
    "p1.to_csv(pathlib.Path.cwd().joinpath('data_float_weighted', 'p1', 'train.tsv'), sep='\\t', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
